{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG16.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMEF8A+hpIO5/zPad5sxKfB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"KCSVbHIRsZMf"},"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from tensorflow.keras.utils import to_categorical\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import img_to_array, array_to_img, ImageDataGenerator\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from keras.regularizers import l2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b1MFJFqPsfd9"},"source":["from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, BatchNormalization, Add, Activation, AveragePooling2D, Dropout\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.optimizers import Adam, SGD\n","from tensorflow.keras.losses import categorical_crossentropy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ZOEoyrRsoee"},"source":["def load_dataset(dataset):\n","  if dataset == 'mnist':\n","    return tf.keras.datasets.mnist.load_data()\n","  elif dataset == 'fashion_mnist':\n","    return tf.keras.datasets.fashion_mnist.load_data()\n","  elif dataset == 'cifar-10':\n","    return tf.keras.datasets.cifar10.load_data()\n","  else:\n","    return -1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r32B2oEestkT"},"source":["def preprocess_dataset(x_train, y_train, x_test, y_test):\n","  # expand the dimension (add the channel axis to MNIST and Fashion_MNIST)\n","  if len(x_train.shape) == 3 :\n","    x_train = tf.expand_dims(x_train, -1)\n","    x_test = tf.expand_dims(x_test, -1)\n","    \n","  # resize the image\n","  x_train = np.asarray([img_to_array(array_to_img(im, scale=False).resize((64,64))) for im in x_train])\n","  x_test = np.asarray([img_to_array(array_to_img(im, scale=False).resize((64,64))) for im in x_test])\n","\n","  # Convert the labels to their one-hot representation\n","  y_train = to_categorical(y_train)\n","  y_test = to_categorical(y_test)\n","\n","  # Normalise the dataset by mean subtraction\n","  x_train = x_train.astype('float32')\n","  x_test = x_test.astype('float32')\n","  x_train_mean = np.mean(x_train, axis=0)\n","  x_train -= x_train_mean\n","  x_test -= x_train_mean\n","\n","  return x_train, y_train, x_test, y_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O9HHYpZYsua0"},"source":["def visualize(pred_labels, test_labels, test_images, dataset_name):\n","  # list to store the index of the success cases and fail cases\n","  success_cases = []\n","  fail_cases = []\n","  for i in range(len(test_labels)):\n","    if test_labels[i].argmax() == pred_labels[i].argmax() and len(success_cases)<5:\n","      success_cases.append(i)\n","    elif test_labels[i].argmax() != pred_labels[i].argmax() and len(fail_cases)<5:\n","      fail_cases.append(i)\n","    if len(success_cases) == 4 and len(fail_cases) == 4:\n","      break\n","  \n","  # cmap = gray from MNIST and fashion_mnist\n","  if len(test_images[0].shape) == 2:\n","    cmap = 'gray'\n","  else:\n","    cmap = None\n","  \n","  # plotting the success cases\n","  fig, ax = plt.subplots(nrows=2, ncols=2)\n","  for row in ax:\n","    for col in row:\n","        col.imshow(test_images[success_cases.pop(0)], interpolation='nearest', cmap=cmap)\n","  fig.suptitle('Success Cases of vgg16 on ' + dataset_name)\n","  plt.show()\n","\n","  # plotting the fail cases\n","  fig, ax = plt.subplots(nrows=2, ncols=2)\n","  for row in ax:\n","    for col in row:\n","        col.imshow(test_images[fail_cases.pop(0)], interpolation='nearest', cmap=cmap)\n","  fig.suptitle('Fail Cases of vgg16 on ' + dataset_name)\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lsIDPYsPsx7m"},"source":["def model_vgg16(image_shape, num_category):\n","  # number of filters\n","  filters = [64, 128, 256, 512, 512]\n","  # number of conv layers\n","  layers = [2, 2, 3, 3, 3]\n","  # using tf.keras sequential API\n","  model = Sequential()\n","  model.add(Input(shape=image_shape))\n","  for l in layers:\n","    f = filters.pop(0)\n","    for _ in range(l):\n","      model.add(Conv2D(filters=f,kernel_size=(3,3),padding=\"same\", activation=\"relu\", kernel_initializer='he_normal',kernel_regularizer=l2(1e-4)))\n","    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n","  model.add(Flatten())\n","  model.add(Dense(units=4096,activation=\"relu\", kernel_initializer='he_normal'))\n","  model.add(Dropout(0.3))\n","  model.add(Dense(units=4096,activation=\"relu\", kernel_initializer='he_normal'))\n","  model.add(Dropout(0.3))\n","  model.add(Dense(units=num_category, activation=\"softmax\", kernel_initializer='he_normal'))\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LS4Biv0ds1M4"},"source":["dataset_name = 'mnist'\n","(train_img, train_lbl), (test_img, test_lbl) = load_dataset(dataset_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b0-JY__otQpa"},"source":["train_images, train_labels, test_images, test_labels = preprocess_dataset(train_img, train_lbl, test_img, test_lbl)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uvGgWtdrtRQ9"},"source":["augment_data = True\n","batch_size = 128\n","validation_percent = 0.1\n","epochs = 100\n","if augment_data:\n","  datagen = ImageDataGenerator(\n","      width_shift_range=0.1,\n","      height_shift_range=0.1,\n","      horizontal_flip=True,\n","      rotation_range=0,\n","      fill_mode='nearest',\n","      validation_split=validation_percent\n","  )\n","  train_iterator = datagen.flow(train_images, train_labels, batch_size=batch_size, subset='training')\n","  validation_iterator = datagen.flow(train_images, train_labels, batch_size=batch_size, subset='validation')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dzuT2m9tVuo"},"source":["vgg16 = model_vgg16(image_shape = train_images[0].shape, num_category = len(train_labels[0]))\n","vgg16.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n","vgg16.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W-zLvbottYwL"},"source":["reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=3, min_lr=0.5e-6)\n","early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n","if augment_data:\n","  history = vgg16.fit(train_iterator, epochs=epochs, steps_per_epoch=len(train_iterator), \n","                                validation_data=validation_iterator, validation_steps=len(validation_iterator), \n","                                callbacks=[reduce_lr, early_stop])\n","else:\n","  history = vgg16.fit(x=train_images, y=train_labels, epochs=epochs, batch_size=batch_size, \n","                      validation_split=validation_percent,\n","                      callbacks=[reduce_lr, early_stop])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Thgu6Lxhtb9g"},"source":["# summarize history for accuracy\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy of vgg16 on ' + dataset_name)\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss of vgg16 on ' + dataset_name)\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z3foX0S0tfRz"},"source":["eval = vgg16.evaluate(test_images, test_labels, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y_l8Qx9VuBjy"},"source":["predictions = vgg16.predict(test_images, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C-KByIZHuELR"},"source":["visualize(predictions, test_labels, test_img, dataset_name)"],"execution_count":null,"outputs":[]}]}